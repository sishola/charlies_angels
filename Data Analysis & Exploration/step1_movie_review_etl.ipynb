{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Notebook imports the list of IMDb URLS and adjusts them so that they pick up the correct reviews URL and seperates the IMDB id from the initial URL. Using the IMDB id, it pulls all the films from the OMDb API and inserts them into Dataframe. Additional clean-up is done, including removing all titles that are not movies. Then, the initial Dataframe and the OMDb Dataframe are merged together before using Beautiful Soup to pull all of the reviews from the URLs. Lastly, the Dataframe is inserted into MongoDB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pMRF5QPj1bH9"
   },
   "outputs": [],
   "source": [
    "#Load dependenices\n",
    "import pandas as pd\n",
    "import requests\n",
    "import pymongo\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0jvomAOS1bIH"
   },
   "outputs": [],
   "source": [
    "# Import file containing imdb movie urls\n",
    "url_df = pd.read_csv('https://charlies-angels.s3.us-east-2.amazonaws.com/movie_urls.txt', names = [\"url\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U1EJPVyl1bIP"
   },
   "outputs": [],
   "source": [
    "# Remove duplicates and reset index\n",
    "url_df = url_df.drop_duplicates()\n",
    "url_df.reset_index(inplace = True, drop = True)\n",
    "\n",
    "# Add a column for Reviews\n",
    "url_df['reviews'] = ''\n",
    "\n",
    "# Add a column for IMDB Movie ID\n",
    "url_df['movie_id'] = url_df['url'].str.replace('/usercomments','').str.replace('http://www.imdb.com/title/','')\n",
    "\n",
    "# Update the URLs to what we want\n",
    "url_df['url'] = url_df['url'].str.replace('usercomments','reviews')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "b6qpbZpxBMEo",
    "outputId": "876151a0-ee44-4975-ca6f-3b9fb327ac7c"
   },
   "outputs": [],
   "source": [
    "# Online Movie Database (OMDB) API URL including API Key and full plot\n",
    "api_url = \"http://www.omdbapi.com/?apikey=baee4093&plot=full\"\n",
    "\n",
    "movie_data = []\n",
    "\n",
    "# Using a for-loop...\n",
    "for movie_id in url_df['movie_id']:\n",
    "    # Use the movie_id to pull data from the API\n",
    "    try:\n",
    "        movie = requests.get(api_url + '&i=' + movie_id).json()\n",
    "        if movie['Response'] == \"True\":\n",
    "            movie_data.append(movie)\n",
    "    except JSONDecodeError:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fJDT_m1iBPcz"
   },
   "outputs": [],
   "source": [
    "# Create a pandas Dataframe using movie_data\n",
    "omdb_df = pd.DataFrame(movie_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xm_qCFeMBUhB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 6018 entries in the movie_only dataframe.\n"
     ]
    }
   ],
   "source": [
    "# Create a copy of the dataframe for cleaner manipulation\n",
    "movie_only = omdb_df.copy()\n",
    "# Ensure that only movie titles are being used\n",
    "movie_only = movie_only[movie_only['Type'] == 'movie']\n",
    "# Drop any duplicates\n",
    "movie_only = movie_only.drop_duplicates(subset =\"imdbID\") \n",
    "# Drop any rating with N/A\n",
    "movie_only = movie_only[movie_only['imdbRating'] != 'N/A']\n",
    "# Convert the rating column to a numeric one\n",
    "movie_only['imdbRating'] = pd.to_numeric(movie_only['imdbRating'])\n",
    "\n",
    "# Check the number of entries\n",
    "unique_films = movie_only['imdbID'].nunique()\n",
    "print(f'There are {unique_films} entries in the movie_only dataframe.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4NBz4-Q5FhZq"
   },
   "outputs": [],
   "source": [
    "# Merge both dataframes together using an inner join \n",
    "full_df = pd.merge(url_df, movie_only, left_on='movie_id', right_on='imdbID', how='inner')\n",
    "\n",
    "#Rename imdbRating to label, since Naive Bayes requires it\n",
    "full_df.rename(columns={'imdbRating' : 'label_orig'}, inplace=True)\n",
    "# Clean up the columns to ensure only the columns we need will be used\n",
    "full_df = full_df[['url', 'reviews', 'movie_id', 'Title', 'Year', 'Genre', 'Actors','Plot', 'Poster', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9fM-aq_q1bIu"
   },
   "outputs": [],
   "source": [
    "# Retrieve reviews\n",
    "for idx in range(len(full_df)):\n",
    "    reviews = ''\n",
    "    \n",
    "    response = requests.get(full_df.loc[idx, 'url'])\n",
    "    soup = BeautifulSoup(response.text, 'lxml')\n",
    "    results = soup.find_all('div', class_='text show-more__control')\n",
    "    \n",
    "    for result in results:\n",
    "        reviews = reviews + result.text + ' ' \n",
    "    \n",
    "    full_df.loc[idx, ['reviews']] = reviews\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v-WE7wG2NrmM"
   },
   "outputs": [],
   "source": [
    "# Remove any films with blank reviews\n",
    "full_df = full_df[full_df['reviews'] != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oPv1NmVg1bIy"
   },
   "outputs": [],
   "source": [
    "full_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In order to run, please uncomment the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rJ4K9HCt1bI2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertManyResult at 0x1e53eddd688>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create list of dictionaries in order to efficiently insert into MongoDB\n",
    "#movies_dict = full_df.to_dict('records')\n",
    "\n",
    "# MongoDB connection\n",
    "#conn = 'mongodb+srv://general_user:charli3s_ang3ls@cluster0-tyboh.mongodb.net/movie_db?retryWrites=true&w=majority'\n",
    "#client = pymongo.MongoClient(conn)\n",
    "\n",
    "# Declare the collection\n",
    "#collection = client.movie_db.movie_reviews\n",
    "#Drop collection if it exists to prevent duplication\n",
    "#collection.drop()  \n",
    "# Insert all of the documents into the collection\n",
    "#collection.insert_many(movies_dict)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "retrieve_movie_reviews.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
